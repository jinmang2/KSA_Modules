{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7_26_RL_2.ipynb의 사본","version":"0.3.2","provenance":[{"file_id":"1ve5B4YMeogNnACEXUylmoZIaXLhaVliC","timestamp":1564128196309}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SJR4PUEZmKrT","colab_type":"code","outputId":"10ff8ecd-03aa-4d28-97a8-852180f06dd7","executionInfo":{"status":"ok","timestamp":1564105509453,"user_tz":-540,"elapsed":20975,"user":{"displayName":"Jun Seok Ko","photoUrl":"https://lh4.googleusercontent.com/-ocCe_en4JEg/AAAAAAAAAAI/AAAAAAAAAA0/3_y396F5GXw/s64/photo.jpg","userId":"09316774114625797444"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MkyNptPrtvCv","colab_type":"text"},"source":["#q-network_taxi_1"]},{"cell_type":"code","metadata":{"id":"12h03Dvdtxkx","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import random\n","import tensorflow as tf\n","\n","#====== 환경 로딩 =======#\n","env = gym.make('Taxi-v2')\n","\n","#====== 신경망 구현 =======#\n","tf.reset_default_graph()\n","\n","#행동을 선택하는데 사용되는 신경망의 피드-포워드 부분을 구축한다.\n","inputs = tf.placeholder(shape=[1, env.observation_space.n], dtype=tf.float32)  #1*500 matrix\n","weights = tf.Variable(tf.random_uniform([env.observation_space.n,env.action_space.n], 0, 0.01))  #500*6 matrix\n","q_out = tf.matmul(inputs, weights)  #1*6 matrix\n","predict = tf.argmax(q_out,1)\n","\n","# 목표 Q값(ext_q)과 예측 Q값(q_out)의 제곱합을 구함으로써 비용을 얻게 된다.\n","next_q = tf.placeholder(shape=[1,env.action_space.n],dtype=tf.float32)\n","loss = tf.reduce_sum(tf.square(next_q - q_out))\n","trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n","loss_update = trainer.minimize(loss)\n","\n","#====== 신경망 학습하기 =======#\n","init = tf.global_variables_initializer()\n","\n","# 학습 관련 파라미터를 설정한다.\n","gamma = 0.7\n","epsilon = 0.2\n","epsilon_decay = .99\n","episodes = 100\n","\n","total_epochs = 0\n","total_rewards = 0\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for episode in range(episodes):\n","        #환경을 리셋하고 첫번째 새로운 관측값을 얻는다.\n","        state = env.reset()\n","        rewards_this_episode = 0\n","        epochs = 0\n","\n","        done = False\n","        \n","        # q-network \n","        while not done:\n","            #Q-네트워크로부터 (e의 확률로 랜덤한 액션과 함께) 그리디하게 액션을 선택한다.\n","            action, q = sess.run([predict,q_out], feed_dict={inputs:np.identity(env.observation_space.n)[state:state + 1]})\n","            if np.random.rand(1) < epsilon:\n","                action[0] = env.action_space.sample()\n","\n","            #환경으로부터 새로운 상태와 보상을 얻는다.                \n","            next_state, reward, done, info = env.step(action[0])\n","            #새로운 상태를 네트워크에 피드해줌으로써 Q’값을 구한다.\n","            curr_q = sess.run(q_out, feed_dict = {inputs:np.identity(env.observation_space.n)[next_state:next_state+1]})\n","            #maxQ'값을 구하고 선택된 행동에 대한 타겟 값을 설정한다.\n","            max_next_q = np.max(curr_q)\n","            target_q = q\n","            target_q[0, action[0]] = reward + gamma * max_next_q\n","\n","            #타겟과 예측된 Q값을 이용하여 네트워크를 학습시킨다.\n","            info, new_weights = sess.run([loss_update, weights], feed_dict={inputs:np.identity(env.observation_space.n)[state:state+1], next_q:target_q})\n","            rewards_this_episode += reward\n","            state = next_state\n","            epochs += 1\n","        #모델을 학습해 나감에 따라 랜덤 액션의 가능성을 줄여간다.    \n","        epsilon = epsilon * epsilon_decay\n","        \n","        total_epochs += epochs\n","        total_rewards += rewards_this_episode\n","        \n","print (\"Percent of succesful episodes: \" + str(total_rewards/episodes))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVDGw2ts86J_","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"KLUi3Gos9Hp3","colab_type":"text"},"source":["# mountain car dqn"]},{"cell_type":"code","metadata":{"id":"lvps4DjD9Nb7","colab_type":"code","colab":{}},"source":["\"\"\"\n","Deep Q-Network: Mountain Car에 적용한 DQN 예제\n","\"\"\"\n","\n","import numpy as np\n","import tensorflow as tf\n","import gym\n","\n","class DQN:\n","    def __init__(self, learning_rate, gamma, n_features, n_actions, epsilon, parameter_changing_pointer, memory_size):\n","        self.learning_rate = learning_rate  #학습률\n","        self.gamma = gamma            #할인율\n","        self.n_features = n_features  #자동차의 위치(0)와 속도(1)\n","        self.n_actions = n_actions    #왼쪽으로 밀기(0), 보류(1), 오른쪽으로 밀기(2) \n","        self.epsilon = epsilon        #탐욕 정책 시 활용되는 탐욕의 초기 값       \n","        self.batch_size = 100         #재생 메모리로부터 추출되는 표본의 크기\n","        self.experience_counter = 0   #현재 재생 메모리에 저장된 표본의 수\n","        self.experience_limit = memory_size  #재생 메모리의 최대 용량\n","        self.replace_target_pointer = parameter_changing_pointer  #target network 갱신 기준 학습 단계\n","        self.learning_counter = 0                                 #primary network의 학습 단계\n","        self.memory = np.zeros([self.experience_limit,self.n_features*2+2])  #재생 메모리의 초기값  \n","\n","        self.build_networks() #primary network과 target network을 생성\n","        p_params = tf.get_collection('primary_network_parameters')\n","        t_params = tf.get_collection('target_network_parameters')\n","        self.replacing_target_parameters = [tf.assign(t,p) for t,p in zip(t_params,p_params)]\n","\n","        self.sess = tf.Session()\n","        self.sess.run(tf.global_variables_initializer())\n","\n","#========== DQN 모형의 기본 신경망 및 목표 신경망을 설정하는 단계 ============#\n","\n","    def build_networks(self):\n","        hidden_units = 10\n","#.....................................................................#\n","        # Primary Network: 각 10개의 은닉노드를 갖는 2개의 은닉층 \n","        self.s = tf.placeholder(tf.float32,[None,self.n_features])\n","        self.qtarget = tf.placeholder(tf.float32,[None,self.n_actions])\n","\n","        with tf.variable_scope('primary_network'): #변수 볌위를 관리한다.\n","            c = ['primary_network_parameters', \n","\t\t\t\t\ttf.GraphKeys.GLOBAL_VARIABLES]\n","            # first layer\n","            with tf.variable_scope('layer1'):\n","                w1 = tf.get_variable('w1', [self.n_features, hidden_units],\n","\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                b1 = tf.get_variable('b1', [1, hidden_units],\n","\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                l1 = tf.nn.relu(tf.matmul(self.s, w1) + b1)\n","\n","            # second layer\n","            with tf.variable_scope('layer2'):\n","                w2 = tf.get_variable('w2', [hidden_units, self.n_actions],\n","\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                b2 = tf.get_variable('b2', [1, self.n_actions],\n","\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                self.qeval = tf.matmul(l1, w2) + b2\n","\n","        with tf.variable_scope('loss'):\n","                self.loss = tf.reduce_mean(tf.squared_difference(\n","\t\t\t\t\t\tself.qtarget, self.qeval))\n","        with tf.variable_scope('optimiser'):\n","                self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n","\n","#.....................................................................#\n","        # Target Network\n","        self.st = tf.placeholder(tf.float32,[None,self.n_features])\n","\n","        with tf.variable_scope('target_network'):\n","            c = ['target_network_parameters', tf.GraphKeys.GLOBAL_VARIABLES]\n","            # first layer\n","            with tf.variable_scope('layer1'):\n","                w1 = tf.get_variable('w1', [self.n_features, hidden_units],\n","\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                b1 = tf.get_variable('b1', [1, hidden_units],\n","\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                l1 = tf.nn.relu(tf.matmul(self.st, w1) + b1)\n","\n","            # second layer\n","            with tf.variable_scope('layer2'):\n","                w2 = tf.get_variable('w2', [hidden_units, self.n_actions],\n","\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                b2 = tf.get_variable('b2', [1, self.n_actions],\n","\t\t\t\tinitializer=tf.contrib.layers.xavier_initializer(),\n","                                     dtype=tf.float32,collections=c)\n","\n","                self.qt = tf.matmul(l1, w2) + b2\n","\n","#-----------------------------------------------\n","#기본 신경망의 학습 결과를 목표 신경망에 대입하기 위한 세션을 구성한다\n","    def target_params_replaced(self):\n","        self.sess.run(self.replacing_target_parameters)\n","\n","    def store_experience(self,obs,a,r,obs_):\n","        index = self.experience_counter % self.experience_limit\n","        self.memory[index,:] = np.hstack((obs,[a,r],obs_))\n","        self.experience_counter+=1\n","\n","#---------------------------------------------------------------\n","#재생 메모리에 저장된 과거 경험을 설정한 배치 크기만큼 랜덤으로 추출하여 학습 데이터 집합으로 설정한다.\n","    def fit(self):\n","        # sample batch memory from all memory\n","        if self.experience_counter < self.experience_limit:\n","            indices = np.random.choice(self.experience_counter, size=self.batch_size)\n","        else:\n","            indices = np.random.choice(self.experience_limit, size=self.batch_size)\n","\n","        batch = self.memory[indices,:]\n","        qt,qeval = self.sess.run([self.qt,self.qeval],\n","\tfeed_dict={self.st:batch[:,-self.n_features:],self.s:batch[:,:self.n_features]})\n","\n","        qtarget = qeval.copy()    \n","        batch_indices = np.arange(self.batch_size, dtype=np.int32)\n","        actions = self.memory[indices,self.n_features].astype(int)\n","        rewards = self.memory[indices,self.n_features+1]\n","        qtarget[batch_indices,actions] = rewards + self.gamma * np.max(qt,axis=1)\n","\n","        _ = self.sess.run(self.train,feed_dict = {self.s:batch[:,:self.n_features],\n","\t\t\t\t\t\t\tself.qtarget:qtarget})\n","        if self.epsilon < 0.9:\n","            self.epsilon += 0.0002\n","\n","#---------------------------------------------------------------\n","#학습 시 기본 신경망의 가중치를 가져와 목표 신경망의 가중치를 갱신한다.\n","        if self.learning_counter % self.replace_target_pointer == 0:\n","            self.target_params_replaced()\n","            print(\"target parameters changed\")\n","        self.learning_counter += 1\n","\n","#---------------------------------------------------------------\n","#탐욕 정책을 통해 행동을 선택하는 함수를 정의한다.\n","    def epsilon_greedy(self,obs):\n","        #epsilon greedy implementation to choose action\n","        if np.random.uniform(low=0,high=1) < self.epsilon:\n","            return np.argmax(self.sess.run(self.qeval,\n","\t\t\t\t\tfeed_dict={self.s:obs[np.newaxis,:]}))\n","        else:\n","            return np.random.choice(self.n_actions)\n","\n","#---------------------------------------------------------------\n","#DQN 객체를 생성해 에이전트를 학습시키고 결과를 도출하는 단계\n","if __name__ == \"__main__\":\n","    env = gym.make('MountainCar-v0')\n","    env = env.unwrapped\n","    dqn = DQN(learning_rate=0.001, gamma=0.9, n_features=env.observation_space.shape[0], \t n_actions=env.action_space.n, epsilon=0.0, parameter_changing_pointer=500, \n","\t memory_size=5000)\n","\n","    episodes = 10\n","    total_steps = 0\n","\n","    for episode in range(episodes):\n","        steps = 0\t\t\n","        obs = env.reset()\n","        episode_reward = 0\n","        while True:\n","            env.render()\n","            action = dqn.epsilon_greedy(obs)\n","            obs_,reward,terminate,_ = env.step(action)\n","            reward = abs(obs_[0]+0.5)\n","            dqn.store_experience(obs,action,reward,obs_)\n","            if total_steps > 1000:\n","                dqn.fit()\n","            episode_reward+=reward\n","            if terminate:\n","                break\n","            obs = obs_\n","            total_steps+=1\n","            steps+=1\n","        print(\"Episode {} with Reward : {} at epsilon {} in steps {}\".\n","\t\t\tformat(episode+1,episode_reward,dqn.epsilon,steps))\n","\n","    while True:  \n","        env.render()\t\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0oI9DFR9OJ-","colab_type":"text"},"source":["# dddqn gridworld"]},{"cell_type":"code","metadata":{"id":"Z_9q4L_9IOA5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":288},"outputId":"eda903f0-c6c5-4b28-c8f1-0c9256ded5ca","executionInfo":{"status":"ok","timestamp":1564108463750,"user_tz":-540,"elapsed":13293,"user":{"displayName":"Jun Seok Ko","photoUrl":"https://lh4.googleusercontent.com/-ocCe_en4JEg/AAAAAAAAAAI/AAAAAAAAAA0/3_y396F5GXw/s64/photo.jpg","userId":"09316774114625797444"}}},"source":["!pip install scipy==1.1.0"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.3.0\n","    Uninstalling scipy-1.3.0:\n","      Successfully uninstalled scipy-1.3.0\n","Successfully installed scipy-1.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["scipy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"5kb4eB-89RMO","colab_type":"code","outputId":"5d35e2f7-a630-4043-8fe5-4d09511ca61e","executionInfo":{"status":"ok","timestamp":1564111128266,"user_tz":-540,"elapsed":2652562,"user":{"displayName":"Jun Seok Ko","photoUrl":"https://lh4.googleusercontent.com/-ocCe_en4JEg/AAAAAAAAAAI/AAAAAAAAAA0/3_y396F5GXw/s64/photo.jpg","userId":"09316774114625797444"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import division\n","\n","import gym\n","import numpy as np\n","import random\n","import tensorflow as tf\n","import tensorflow.contrib.slim as slim\n","import matplotlib.pyplot as plt\n","import scipy.misc\n","import os\n","import sys\n","sys.path.insert(0, '/content/drive/My Drive/lecture/l_d/p6/강화학습_강의코드/')\n","%matplotlib inline\n","\n","from gridworld import gameEnv\n","\n","#========= 게임 환경 로딩 =========#\n","env = gameEnv(partial=False,size=5)\n","#env = gym.make('Gridworld-v0')\n","\n","#========= 네트워크 구현 =========#\n","class Qnetwork():\n","    def __init__(self,h_size):\n","        #네트워크는 게임으로부터 하나의 프레임을 받아 이를 배열로 만든다 (flattening).\n","        #배열의 크기를 재조절해주고 4개의 컨벌루션 레이어를 거치면서 처리해 준다.\n","        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n","        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n","        self.conv1 = slim.conv2d( \\\n","            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n","        self.conv2 = slim.conv2d( \\\n","            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n","        self.conv3 = slim.conv2d( \\\n","            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n","        self.conv4 = slim.conv2d( \\\n","            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n","        \n","        #마지막 컨벌루션 레이어로부터의 출력값을 취한 후, 이를 어드밴티지 스트림과 값 스트림으로 분리한다. \n","        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n","        self.streamA = slim.flatten(self.streamAC)\n","        self.streamV = slim.flatten(self.streamVC)\n","        self.AW = tf.Variable(tf.random_normal([h_size//2,env.actions]))\n","        self.VW = tf.Variable(tf.random_normal([h_size//2,1]))\n","        self.Advantage = tf.matmul(self.streamA,self.AW)\n","        self.Value = tf.matmul(self.streamV,self.VW)\n","        \n","        #최종 Q-값을 얻기 위해 어드밴티지 스트림과 값 스트림을 조합해 준다. \n","        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n","        self.predict = tf.argmax(self.Qout,1)\n","        \n","        #타겟 Q 값과 예측 Q 값 간의 제곱합 차를 취함으로써 비용을 구한다.\n","        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n","        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n","        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n","        \n","        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n","        \n","        self.td_error = tf.square(self.targetQ - self.Q)\n","        self.loss = tf.reduce_mean(self.td_error)\n","        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n","        self.updateModel = self.trainer.minimize(self.loss)\n","        \n","#========= 경험 재생 =========#\n","#다음 클래스는 경험과 샘플을 저장하고 랜덤하게 신경망을 학습시킨다 \n","        \n","class experience_buffer():\n","    def __init__(self, buffer_size = 50000):\n","        self.buffer = []\n","        self.buffer_size = buffer_size\n","    \n","    def add(self,experience):\n","        if len(self.buffer) + len(experience) >= self.buffer_size:\n","            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n","        self.buffer.extend(experience)\n","            \n","    def sample(self,size):\n","        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])        \n","\n","#다음은 게임의 프레임의 사이즈를 조절해 주는 간단한 함수이다.\n","def processState(states):\n","    return np.reshape(states,[21168])\n","\n","#아래 함수들은 1차 신경망의 파라미터와 함께 목표 신경망의 파라미터를 업데이트하게 해준다\n","def updateTargetGraph(tfVars,tau):\n","    total_vars = len(tfVars)\n","    op_holder = []\n","    for idx,var in enumerate(tfVars[0:total_vars//2]):\n","        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n","    return op_holder\n","\n","def updateTarget(op_holder,sess):\n","    for op in op_holder:\n","        sess.run(op)\n","\n","#========= 신경망 학습 =========#\n","\n","#모든 학습 파라미터를 설정한다            \n","batch_size = 32 #각 학습 단계에서 사용할 경험의 수\n","update_freq = 4 #학습 단계 기준의 업데이트 주기 \n","y = .99 #타겟 Q-값에 대한 할인 계수\n","startE = 1 #시작 시 랜덤 액션의 가능성\n","endE = 0.1 #종료 시 랜덤 액션의 가능성\n","anneling_steps = 10000. #startE에서 endE로 줄어드는데 필요한 학습 단계 수\n","num_episodes = 10000 #네트워크를 학습시키기 위한 게임 환경 에피소드의 수\n","pre_train_steps = 10000 #학습 시작 전 랜덤 액션의 단계 수\n","max_epLength = 50 #허용되는 최대 에피소드 길이\n","load_model = False #저장된 모델을 로딩할 지 여부\n","path = \"./dqn\" #모델을 저장할 경로\n","h_size = 512 #어드밴티지 스트림과 값 스트림으로 분리되기 전의 마지막 컨벌루션 레이어의 크기\n","tau = 0.001 #타겟 네트워크를 제1네트워크로 업데이트시켜 가는 비율\n","\n","tf.reset_default_graph()\n","mainQN = Qnetwork(h_size)\n","targetQN = Qnetwork(h_size)\n","\n","init = tf.global_variables_initializer()\n","\n","saver = tf.train.Saver()\n","\n","trainables = tf.trainable_variables()\n","\n","targetOps = updateTargetGraph(trainables,tau)\n","\n","myBuffer = experience_buffer()\n","\n","#랜덤 액션이 감소하는 비율을 설정 \n","e = startE\n","stepDrop = (startE - endE)/anneling_steps\n","\n","#전체 보상과 에피소드 별 단계 수를 저장할 리스트를 생성\n","jList = []\n","rList = []\n","total_steps = 0\n","\n","#모델이 저장될 경로 생성\n","if not os.path.exists(path):\n","    os.makedirs(path)\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","    if load_model == True:\n","        print('Loading Model...')\n","        ckpt = tf.train.get_checkpoint_state(path)\n","        saver.restore(sess,ckpt.model_checkpoint_path)\n","    updateTarget(targetOps,sess) #타겟 네트워크가 제1네트워크와 동일하도록 설정\n","    for i in range(num_episodes):\n","        episodeBuffer = experience_buffer()\n","        #환경을 리셋하고 첫번째 관찰 얻기\n","        s = env.reset()\n","        s = processState(s)\n","        d = False\n","        rAll = 0\n","        j = 0\n","        #Q-네트워크\n","        while j < max_epLength: #만약 에이전트가 블록에 도달하기 위해 200회 이상 시도하면 종료\n","            j+=1\n","            # Q-네트워크로부터 (e의 확률로 랜덤한 액션과 함께) 그리디하게 액션을 선택한다.\n","            if np.random.rand(1) < e or total_steps < pre_train_steps:\n","                a = np.random.randint(0,4)\n","            else:\n","                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n","            s1,r,d = env.step(a)\n","            s1 = processState(s1)\n","            total_steps += 1\n","            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #에피소드 버퍼에 경험을 저장\n","            \n","            if total_steps > pre_train_steps:\n","                if e > endE:\n","                    e -= stepDrop\n","                \n","                if total_steps % (update_freq) == 0:\n","                    trainBatch = myBuffer.sample(batch_size) #경험에서 특정 부분을 랜덤하게 획득\n","                    #타겟 Q-값에 대해 double DQN 업데이트를 수행\n","                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n","                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n","                    end_multiplier = -(trainBatch[:,4] - 1)\n","                    doubleQ = Q2[range(batch_size),Q1]\n","                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n","                    #타겟 값을 이용해 네트워크를 업데이트\n","                    _ = sess.run(mainQN.updateModel, \\\n","                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n","                    \n","                    updateTarget(targetOps,sess) #타겟 네트워크가 제1네트워크와 동일하도록 설정\n","            rAll += r\n","            s = s1\n","            \n","            if d == True:\n","\n","                break\n","        \n","        myBuffer.add(episodeBuffer.buffer)\n","        jList.append(j)\n","        rList.append(rAll)\n","        #정기적으로 모델 저장\n","        if i % 1000 == 0:\n","            saver.save(sess,path+'/model-'+str(i)+'.cptk')\n","            print(\"Saved Model\")\n","        if len(rList) % 10 == 0:\n","            print(total_steps,np.mean(rList[-10:]), e)\n","    saver.save(sess,path+'/model-'+str(i)+'.cptk')\n","print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")\n","\n","#========= 신경망 학습 확인하기 =========#\n","#시간의 흐름에 따른 평균 보상\n","\n","rMat = np.resize(np.array(rList),[len(rList)//100,100])\n","rMean = np.average(rMat,1)\n","plt.plot(rMean)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0726 02:34:38.365316 139907771885440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Saved Model\n","500 2.6 1\n","1000 0.7 1\n","1500 2.9 1\n","2000 2.1 1\n","2500 2.2 1\n","3000 2.4 1\n","3500 3.0 1\n","4000 0.9 1\n","4500 1.8 1\n","5000 1.6 1\n","5500 1.7 1\n","6000 3.7 1\n","6500 1.1 1\n","7000 1.2 1\n","7500 2.4 1\n","8000 2.5 1\n","8500 2.9 1\n","9000 3.0 1\n","9500 2.2 1\n","10000 2.3 1\n","10500 0.3 0.9549999999999828\n","11000 2.3 0.9099999999999655\n","11500 1.2 0.8649999999999483\n","12000 1.7 0.819999999999931\n","12500 2.3 0.7749999999999138\n","13000 1.3 0.7299999999998965\n","13500 1.6 0.6849999999998793\n","14000 0.7 0.639999999999862\n","14500 1.1 0.5949999999998448\n","15000 1.0 0.5499999999998275\n","15500 1.3 0.5049999999998103\n","16000 2.9 0.4599999999998177\n","16500 0.6 0.41499999999982823\n","17000 1.9 0.36999999999983874\n","17500 0.7 0.32499999999984924\n","18000 2.1 0.27999999999985975\n","18500 1.4 0.23499999999986562\n","19000 1.1 0.18999999999986225\n","19500 0.9 0.14499999999985888\n","20000 0.8 0.09999999999985551\n","20500 0.6 0.09999999999985551\n","21000 0.5 0.09999999999985551\n","21500 0.3 0.09999999999985551\n","22000 1.3 0.09999999999985551\n","22500 0.1 0.09999999999985551\n","23000 0.0 0.09999999999985551\n","23500 0.9 0.09999999999985551\n","24000 1.4 0.09999999999985551\n","24500 1.4 0.09999999999985551\n","25000 0.5 0.09999999999985551\n","25500 1.5 0.09999999999985551\n","26000 1.4 0.09999999999985551\n","26500 0.0 0.09999999999985551\n","27000 1.0 0.09999999999985551\n","27500 0.6 0.09999999999985551\n","28000 0.6 0.09999999999985551\n","28500 1.1 0.09999999999985551\n","29000 1.0 0.09999999999985551\n","29500 0.2 0.09999999999985551\n","30000 1.6 0.09999999999985551\n","30500 1.0 0.09999999999985551\n","31000 1.9 0.09999999999985551\n","31500 1.0 0.09999999999985551\n","32000 0.9 0.09999999999985551\n","32500 0.8 0.09999999999985551\n","33000 0.6 0.09999999999985551\n","33500 1.2 0.09999999999985551\n","34000 1.3 0.09999999999985551\n","34500 2.6 0.09999999999985551\n","35000 0.5 0.09999999999985551\n","35500 1.6 0.09999999999985551\n","36000 2.2 0.09999999999985551\n","36500 1.1 0.09999999999985551\n","37000 0.9 0.09999999999985551\n","37500 0.0 0.09999999999985551\n","38000 1.3 0.09999999999985551\n","38500 1.2 0.09999999999985551\n","39000 1.5 0.09999999999985551\n","39500 1.6 0.09999999999985551\n","40000 1.4 0.09999999999985551\n","40500 2.2 0.09999999999985551\n","41000 1.1 0.09999999999985551\n","41500 0.6 0.09999999999985551\n","42000 0.3 0.09999999999985551\n","42500 0.5 0.09999999999985551\n","43000 1.4 0.09999999999985551\n","43500 0.5 0.09999999999985551\n","44000 2.1 0.09999999999985551\n","44500 1.5 0.09999999999985551\n","45000 1.9 0.09999999999985551\n","45500 0.6 0.09999999999985551\n","46000 1.1 0.09999999999985551\n","46500 1.2 0.09999999999985551\n","47000 1.5 0.09999999999985551\n","47500 1.6 0.09999999999985551\n","48000 1.4 0.09999999999985551\n","48500 1.3 0.09999999999985551\n","49000 0.7 0.09999999999985551\n","49500 1.4 0.09999999999985551\n","50000 1.0 0.09999999999985551\n","Saved Model\n","50500 0.6 0.09999999999985551\n","51000 1.1 0.09999999999985551\n","51500 1.3 0.09999999999985551\n","52000 1.3 0.09999999999985551\n","52500 0.5 0.09999999999985551\n","53000 1.0 0.09999999999985551\n","53500 0.7 0.09999999999985551\n","54000 2.3 0.09999999999985551\n","54500 1.1 0.09999999999985551\n","55000 1.7 0.09999999999985551\n","55500 1.7 0.09999999999985551\n","56000 1.0 0.09999999999985551\n","56500 1.0 0.09999999999985551\n","57000 1.4 0.09999999999985551\n","57500 1.4 0.09999999999985551\n","58000 1.6 0.09999999999985551\n","58500 1.2 0.09999999999985551\n","59000 2.3 0.09999999999985551\n","59500 0.9 0.09999999999985551\n","60000 1.6 0.09999999999985551\n","60500 1.4 0.09999999999985551\n","61000 1.5 0.09999999999985551\n","61500 1.8 0.09999999999985551\n","62000 1.8 0.09999999999985551\n","62500 1.1 0.09999999999985551\n","63000 0.9 0.09999999999985551\n","63500 1.0 0.09999999999985551\n","64000 2.0 0.09999999999985551\n","64500 1.5 0.09999999999985551\n","65000 2.4 0.09999999999985551\n","65500 2.1 0.09999999999985551\n","66000 1.3 0.09999999999985551\n","66500 0.6 0.09999999999985551\n","67000 2.3 0.09999999999985551\n","67500 3.2 0.09999999999985551\n","68000 2.9 0.09999999999985551\n","68500 2.1 0.09999999999985551\n","69000 1.9 0.09999999999985551\n","69500 1.6 0.09999999999985551\n","70000 2.7 0.09999999999985551\n","70500 1.4 0.09999999999985551\n","71000 2.8 0.09999999999985551\n","71500 1.7 0.09999999999985551\n","72000 2.8 0.09999999999985551\n","72500 0.8 0.09999999999985551\n","73000 3.4 0.09999999999985551\n","73500 2.3 0.09999999999985551\n","74000 2.5 0.09999999999985551\n","74500 3.0 0.09999999999985551\n","75000 4.7 0.09999999999985551\n","75500 2.7 0.09999999999985551\n","76000 1.7 0.09999999999985551\n","76500 3.9 0.09999999999985551\n","77000 2.6 0.09999999999985551\n","77500 3.1 0.09999999999985551\n","78000 2.1 0.09999999999985551\n","78500 3.4 0.09999999999985551\n","79000 1.5 0.09999999999985551\n","79500 4.6 0.09999999999985551\n","80000 2.2 0.09999999999985551\n","80500 3.7 0.09999999999985551\n","81000 2.1 0.09999999999985551\n","81500 3.8 0.09999999999985551\n","82000 2.8 0.09999999999985551\n","82500 5.5 0.09999999999985551\n","83000 4.3 0.09999999999985551\n","83500 6.0 0.09999999999985551\n","84000 3.2 0.09999999999985551\n","84500 3.9 0.09999999999985551\n","85000 5.4 0.09999999999985551\n","85500 5.4 0.09999999999985551\n","86000 5.8 0.09999999999985551\n","86500 7.5 0.09999999999985551\n","87000 3.1 0.09999999999985551\n","87500 3.9 0.09999999999985551\n","88000 5.3 0.09999999999985551\n","88500 3.6 0.09999999999985551\n","89000 5.4 0.09999999999985551\n","89500 6.0 0.09999999999985551\n","90000 5.1 0.09999999999985551\n","90500 5.5 0.09999999999985551\n","91000 3.4 0.09999999999985551\n","91500 4.5 0.09999999999985551\n","92000 8.1 0.09999999999985551\n","92500 4.7 0.09999999999985551\n","93000 7.9 0.09999999999985551\n","93500 4.9 0.09999999999985551\n","94000 5.5 0.09999999999985551\n","94500 8.7 0.09999999999985551\n","95000 7.7 0.09999999999985551\n","95500 9.1 0.09999999999985551\n","96000 9.1 0.09999999999985551\n","96500 10.1 0.09999999999985551\n","97000 5.3 0.09999999999985551\n","97500 9.6 0.09999999999985551\n","98000 10.7 0.09999999999985551\n","98500 7.3 0.09999999999985551\n","99000 11.0 0.09999999999985551\n","99500 12.2 0.09999999999985551\n","100000 9.9 0.09999999999985551\n","Saved Model\n","100500 11.2 0.09999999999985551\n","101000 13.4 0.09999999999985551\n","101500 10.8 0.09999999999985551\n","102000 11.5 0.09999999999985551\n","102500 10.1 0.09999999999985551\n","103000 8.8 0.09999999999985551\n","103500 11.7 0.09999999999985551\n","104000 14.4 0.09999999999985551\n","104500 11.0 0.09999999999985551\n","105000 10.0 0.09999999999985551\n","105500 14.2 0.09999999999985551\n","106000 13.9 0.09999999999985551\n","106500 14.6 0.09999999999985551\n","107000 12.8 0.09999999999985551\n","107500 14.4 0.09999999999985551\n","108000 16.3 0.09999999999985551\n","108500 13.9 0.09999999999985551\n","109000 17.8 0.09999999999985551\n","109500 16.7 0.09999999999985551\n","110000 11.5 0.09999999999985551\n","110500 12.2 0.09999999999985551\n","111000 12.9 0.09999999999985551\n","111500 14.2 0.09999999999985551\n","112000 18.2 0.09999999999985551\n","112500 15.8 0.09999999999985551\n","113000 16.5 0.09999999999985551\n","113500 20.4 0.09999999999985551\n","114000 14.4 0.09999999999985551\n","114500 14.6 0.09999999999985551\n","115000 17.5 0.09999999999985551\n","115500 17.3 0.09999999999985551\n","116000 17.7 0.09999999999985551\n","116500 17.4 0.09999999999985551\n","117000 16.6 0.09999999999985551\n","117500 13.1 0.09999999999985551\n","118000 13.5 0.09999999999985551\n","118500 17.0 0.09999999999985551\n","119000 14.0 0.09999999999985551\n","119500 19.8 0.09999999999985551\n","120000 13.6 0.09999999999985551\n","120500 17.1 0.09999999999985551\n","121000 17.4 0.09999999999985551\n","121500 13.7 0.09999999999985551\n","122000 18.7 0.09999999999985551\n","122500 17.1 0.09999999999985551\n","123000 18.0 0.09999999999985551\n","123500 13.7 0.09999999999985551\n","124000 15.8 0.09999999999985551\n","124500 16.3 0.09999999999985551\n","125000 16.2 0.09999999999985551\n","125500 17.7 0.09999999999985551\n","126000 18.3 0.09999999999985551\n","126500 16.7 0.09999999999985551\n","127000 17.9 0.09999999999985551\n","127500 18.1 0.09999999999985551\n","128000 14.8 0.09999999999985551\n","128500 17.0 0.09999999999985551\n","129000 17.8 0.09999999999985551\n","129500 18.3 0.09999999999985551\n","130000 18.2 0.09999999999985551\n","130500 14.9 0.09999999999985551\n","131000 18.0 0.09999999999985551\n","131500 16.2 0.09999999999985551\n","132000 19.5 0.09999999999985551\n","132500 18.5 0.09999999999985551\n","133000 16.7 0.09999999999985551\n","133500 15.1 0.09999999999985551\n","134000 18.6 0.09999999999985551\n","134500 20.4 0.09999999999985551\n","135000 20.4 0.09999999999985551\n","135500 17.2 0.09999999999985551\n","136000 19.0 0.09999999999985551\n","136500 19.3 0.09999999999985551\n","137000 18.2 0.09999999999985551\n","137500 19.6 0.09999999999985551\n","138000 20.5 0.09999999999985551\n","138500 20.7 0.09999999999985551\n","139000 22.0 0.09999999999985551\n","139500 20.9 0.09999999999985551\n","140000 17.6 0.09999999999985551\n","140500 18.0 0.09999999999985551\n","141000 19.0 0.09999999999985551\n","141500 22.5 0.09999999999985551\n","142000 16.1 0.09999999999985551\n","142500 20.9 0.09999999999985551\n","143000 22.1 0.09999999999985551\n","143500 19.6 0.09999999999985551\n","144000 19.2 0.09999999999985551\n","144500 20.0 0.09999999999985551\n","145000 16.0 0.09999999999985551\n","145500 17.9 0.09999999999985551\n","146000 16.4 0.09999999999985551\n","146500 18.4 0.09999999999985551\n","147000 20.5 0.09999999999985551\n","147500 21.2 0.09999999999985551\n","148000 17.1 0.09999999999985551\n","148500 19.2 0.09999999999985551\n","149000 20.7 0.09999999999985551\n","149500 21.0 0.09999999999985551\n","150000 19.8 0.09999999999985551\n","Saved Model\n","150500 20.4 0.09999999999985551\n","151000 17.7 0.09999999999985551\n","151500 20.6 0.09999999999985551\n","152000 19.4 0.09999999999985551\n","152500 21.0 0.09999999999985551\n","153000 22.0 0.09999999999985551\n","153500 21.1 0.09999999999985551\n","154000 22.2 0.09999999999985551\n","154500 18.2 0.09999999999985551\n","155000 19.3 0.09999999999985551\n","155500 16.5 0.09999999999985551\n","156000 18.6 0.09999999999985551\n","156500 21.7 0.09999999999985551\n","157000 19.8 0.09999999999985551\n","157500 17.1 0.09999999999985551\n","158000 15.9 0.09999999999985551\n","158500 20.8 0.09999999999985551\n","159000 20.6 0.09999999999985551\n","159500 20.6 0.09999999999985551\n","160000 17.1 0.09999999999985551\n","160500 17.5 0.09999999999985551\n","161000 22.7 0.09999999999985551\n","161500 19.4 0.09999999999985551\n","162000 21.8 0.09999999999985551\n","162500 20.1 0.09999999999985551\n","163000 18.9 0.09999999999985551\n","163500 21.5 0.09999999999985551\n","164000 21.3 0.09999999999985551\n","164500 22.6 0.09999999999985551\n","165000 21.9 0.09999999999985551\n","165500 19.8 0.09999999999985551\n","166000 18.2 0.09999999999985551\n","166500 22.4 0.09999999999985551\n","167000 20.4 0.09999999999985551\n","167500 21.1 0.09999999999985551\n","168000 24.2 0.09999999999985551\n","168500 20.6 0.09999999999985551\n","169000 20.6 0.09999999999985551\n","169500 20.5 0.09999999999985551\n","170000 19.9 0.09999999999985551\n","170500 22.5 0.09999999999985551\n","171000 21.7 0.09999999999985551\n","171500 19.5 0.09999999999985551\n","172000 20.6 0.09999999999985551\n","172500 20.5 0.09999999999985551\n","173000 21.2 0.09999999999985551\n","173500 21.3 0.09999999999985551\n","174000 22.7 0.09999999999985551\n","174500 21.6 0.09999999999985551\n","175000 20.8 0.09999999999985551\n","175500 19.0 0.09999999999985551\n","176000 22.6 0.09999999999985551\n","176500 22.1 0.09999999999985551\n","177000 19.6 0.09999999999985551\n","177500 19.5 0.09999999999985551\n","178000 21.7 0.09999999999985551\n","178500 19.6 0.09999999999985551\n","179000 21.3 0.09999999999985551\n","179500 21.3 0.09999999999985551\n","180000 20.1 0.09999999999985551\n","180500 21.9 0.09999999999985551\n","181000 19.5 0.09999999999985551\n","181500 19.5 0.09999999999985551\n","182000 21.3 0.09999999999985551\n","182500 20.7 0.09999999999985551\n","183000 22.5 0.09999999999985551\n","183500 22.1 0.09999999999985551\n","184000 23.5 0.09999999999985551\n","184500 22.5 0.09999999999985551\n","185000 20.6 0.09999999999985551\n","185500 21.7 0.09999999999985551\n","186000 21.8 0.09999999999985551\n","186500 20.5 0.09999999999985551\n","187000 20.2 0.09999999999985551\n","187500 21.6 0.09999999999985551\n","188000 20.5 0.09999999999985551\n","188500 20.4 0.09999999999985551\n","189000 20.0 0.09999999999985551\n","189500 19.9 0.09999999999985551\n","190000 21.5 0.09999999999985551\n","190500 21.6 0.09999999999985551\n","191000 23.2 0.09999999999985551\n","191500 21.6 0.09999999999985551\n","192000 23.0 0.09999999999985551\n","192500 23.5 0.09999999999985551\n","193000 18.9 0.09999999999985551\n","193500 21.2 0.09999999999985551\n","194000 21.9 0.09999999999985551\n","194500 20.2 0.09999999999985551\n","195000 22.0 0.09999999999985551\n","195500 18.9 0.09999999999985551\n","196000 19.1 0.09999999999985551\n","196500 22.2 0.09999999999985551\n","197000 21.9 0.09999999999985551\n","197500 21.7 0.09999999999985551\n","198000 18.9 0.09999999999985551\n","198500 25.2 0.09999999999985551\n","199000 21.9 0.09999999999985551\n","199500 22.1 0.09999999999985551\n","200000 21.4 0.09999999999985551\n","Saved Model\n","200500 20.0 0.09999999999985551\n","201000 19.9 0.09999999999985551\n","201500 20.9 0.09999999999985551\n","202000 21.5 0.09999999999985551\n","202500 18.8 0.09999999999985551\n","203000 20.0 0.09999999999985551\n","203500 21.7 0.09999999999985551\n","204000 22.0 0.09999999999985551\n","204500 21.7 0.09999999999985551\n","205000 22.1 0.09999999999985551\n","205500 18.2 0.09999999999985551\n","206000 19.3 0.09999999999985551\n","206500 22.8 0.09999999999985551\n","207000 20.8 0.09999999999985551\n","207500 19.6 0.09999999999985551\n","208000 23.0 0.09999999999985551\n","208500 19.9 0.09999999999985551\n","209000 22.5 0.09999999999985551\n","209500 19.4 0.09999999999985551\n","210000 22.5 0.09999999999985551\n","210500 20.6 0.09999999999985551\n","211000 21.6 0.09999999999985551\n","211500 22.2 0.09999999999985551\n","212000 22.9 0.09999999999985551\n","212500 22.7 0.09999999999985551\n","213000 21.5 0.09999999999985551\n","213500 22.2 0.09999999999985551\n","214000 21.8 0.09999999999985551\n","214500 22.3 0.09999999999985551\n","215000 21.3 0.09999999999985551\n","215500 23.0 0.09999999999985551\n","216000 22.8 0.09999999999985551\n","216500 19.7 0.09999999999985551\n","217000 24.7 0.09999999999985551\n","217500 21.8 0.09999999999985551\n","218000 20.3 0.09999999999985551\n","218500 21.2 0.09999999999985551\n","219000 20.3 0.09999999999985551\n","219500 21.3 0.09999999999985551\n","220000 22.3 0.09999999999985551\n","220500 19.7 0.09999999999985551\n","221000 21.2 0.09999999999985551\n","221500 21.4 0.09999999999985551\n","222000 22.6 0.09999999999985551\n","222500 21.0 0.09999999999985551\n","223000 19.8 0.09999999999985551\n","223500 21.1 0.09999999999985551\n","224000 22.3 0.09999999999985551\n","224500 23.8 0.09999999999985551\n","225000 22.5 0.09999999999985551\n","225500 23.1 0.09999999999985551\n","226000 21.8 0.09999999999985551\n","226500 21.7 0.09999999999985551\n","227000 20.4 0.09999999999985551\n","227500 23.0 0.09999999999985551\n","228000 21.3 0.09999999999985551\n","228500 21.9 0.09999999999985551\n","229000 21.4 0.09999999999985551\n","229500 22.3 0.09999999999985551\n","230000 21.2 0.09999999999985551\n","230500 20.8 0.09999999999985551\n","231000 23.1 0.09999999999985551\n","231500 19.9 0.09999999999985551\n","232000 21.5 0.09999999999985551\n","232500 21.8 0.09999999999985551\n","233000 19.1 0.09999999999985551\n","233500 21.8 0.09999999999985551\n","234000 22.3 0.09999999999985551\n","234500 22.6 0.09999999999985551\n","235000 20.7 0.09999999999985551\n","235500 19.6 0.09999999999985551\n","236000 21.4 0.09999999999985551\n","236500 22.1 0.09999999999985551\n","237000 23.7 0.09999999999985551\n","237500 22.0 0.09999999999985551\n","238000 22.9 0.09999999999985551\n","238500 23.9 0.09999999999985551\n","239000 22.1 0.09999999999985551\n","239500 22.5 0.09999999999985551\n","240000 21.8 0.09999999999985551\n","240500 21.5 0.09999999999985551\n","241000 23.3 0.09999999999985551\n","241500 20.7 0.09999999999985551\n","242000 23.1 0.09999999999985551\n","242500 23.0 0.09999999999985551\n","243000 20.5 0.09999999999985551\n","243500 21.0 0.09999999999985551\n","244000 22.8 0.09999999999985551\n","244500 23.8 0.09999999999985551\n","245000 19.6 0.09999999999985551\n","245500 23.5 0.09999999999985551\n","246000 21.0 0.09999999999985551\n","246500 19.5 0.09999999999985551\n","247000 22.2 0.09999999999985551\n","247500 22.8 0.09999999999985551\n","248000 22.2 0.09999999999985551\n","248500 18.8 0.09999999999985551\n","249000 22.2 0.09999999999985551\n","249500 20.5 0.09999999999985551\n","250000 19.9 0.09999999999985551\n"],"name":"stdout"},{"output_type":"stream","text":["W0726 02:56:10.143735 139907771885440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["Saved Model\n","250500 19.5 0.09999999999985551\n","251000 22.9 0.09999999999985551\n","251500 21.8 0.09999999999985551\n","252000 18.1 0.09999999999985551\n","252500 21.1 0.09999999999985551\n","253000 22.6 0.09999999999985551\n","253500 21.9 0.09999999999985551\n","254000 18.9 0.09999999999985551\n","254500 22.3 0.09999999999985551\n","255000 24.3 0.09999999999985551\n","255500 24.1 0.09999999999985551\n","256000 18.8 0.09999999999985551\n","256500 21.9 0.09999999999985551\n","257000 17.6 0.09999999999985551\n","257500 19.7 0.09999999999985551\n","258000 21.2 0.09999999999985551\n","258500 21.0 0.09999999999985551\n","259000 22.8 0.09999999999985551\n","259500 21.0 0.09999999999985551\n","260000 21.3 0.09999999999985551\n","260500 22.4 0.09999999999985551\n","261000 20.9 0.09999999999985551\n","261500 21.6 0.09999999999985551\n","262000 19.7 0.09999999999985551\n","262500 20.3 0.09999999999985551\n","263000 21.5 0.09999999999985551\n","263500 22.1 0.09999999999985551\n","264000 21.6 0.09999999999985551\n","264500 19.8 0.09999999999985551\n","265000 21.3 0.09999999999985551\n","265500 20.0 0.09999999999985551\n","266000 22.0 0.09999999999985551\n","266500 21.5 0.09999999999985551\n","267000 19.7 0.09999999999985551\n","267500 23.7 0.09999999999985551\n","268000 24.1 0.09999999999985551\n","268500 21.6 0.09999999999985551\n","269000 24.0 0.09999999999985551\n","269500 19.8 0.09999999999985551\n","270000 21.8 0.09999999999985551\n","270500 21.2 0.09999999999985551\n","271000 22.2 0.09999999999985551\n","271500 22.1 0.09999999999985551\n","272000 20.7 0.09999999999985551\n","272500 22.0 0.09999999999985551\n","273000 23.4 0.09999999999985551\n","273500 22.9 0.09999999999985551\n","274000 24.3 0.09999999999985551\n","274500 19.1 0.09999999999985551\n","275000 21.9 0.09999999999985551\n","275500 23.8 0.09999999999985551\n","276000 20.5 0.09999999999985551\n","276500 21.9 0.09999999999985551\n","277000 21.1 0.09999999999985551\n","277500 21.5 0.09999999999985551\n","278000 22.5 0.09999999999985551\n","278500 21.8 0.09999999999985551\n","279000 22.7 0.09999999999985551\n","279500 23.1 0.09999999999985551\n","280000 21.3 0.09999999999985551\n","280500 23.7 0.09999999999985551\n","281000 22.6 0.09999999999985551\n","281500 21.8 0.09999999999985551\n","282000 21.1 0.09999999999985551\n","282500 20.8 0.09999999999985551\n","283000 20.7 0.09999999999985551\n","283500 22.4 0.09999999999985551\n","284000 23.3 0.09999999999985551\n","284500 23.2 0.09999999999985551\n","285000 21.4 0.09999999999985551\n","285500 22.9 0.09999999999985551\n","286000 24.0 0.09999999999985551\n","286500 22.5 0.09999999999985551\n","287000 21.7 0.09999999999985551\n","287500 21.0 0.09999999999985551\n","288000 22.3 0.09999999999985551\n","288500 21.0 0.09999999999985551\n","289000 21.5 0.09999999999985551\n","289500 22.2 0.09999999999985551\n","290000 22.8 0.09999999999985551\n","290500 24.3 0.09999999999985551\n","291000 21.9 0.09999999999985551\n","291500 21.8 0.09999999999985551\n","292000 23.3 0.09999999999985551\n","292500 22.4 0.09999999999985551\n","293000 21.7 0.09999999999985551\n","293500 22.2 0.09999999999985551\n","294000 20.8 0.09999999999985551\n","294500 22.3 0.09999999999985551\n","295000 22.9 0.09999999999985551\n","295500 22.5 0.09999999999985551\n","296000 23.1 0.09999999999985551\n","296500 22.5 0.09999999999985551\n","297000 21.8 0.09999999999985551\n","297500 21.9 0.09999999999985551\n","298000 22.1 0.09999999999985551\n","298500 21.3 0.09999999999985551\n","299000 22.3 0.09999999999985551\n","299500 22.8 0.09999999999985551\n","300000 22.2 0.09999999999985551\n","Saved Model\n","300500 20.8 0.09999999999985551\n","301000 19.4 0.09999999999985551\n","301500 21.5 0.09999999999985551\n","302000 19.7 0.09999999999985551\n","302500 20.9 0.09999999999985551\n","303000 21.5 0.09999999999985551\n","303500 23.4 0.09999999999985551\n","304000 21.0 0.09999999999985551\n","304500 20.7 0.09999999999985551\n","305000 23.5 0.09999999999985551\n","305500 21.7 0.09999999999985551\n","306000 23.6 0.09999999999985551\n","306500 21.6 0.09999999999985551\n","307000 20.6 0.09999999999985551\n","307500 19.6 0.09999999999985551\n","308000 22.5 0.09999999999985551\n","308500 22.9 0.09999999999985551\n","309000 21.0 0.09999999999985551\n","309500 21.3 0.09999999999985551\n","310000 21.3 0.09999999999985551\n","310500 20.1 0.09999999999985551\n","311000 23.1 0.09999999999985551\n","311500 23.5 0.09999999999985551\n","312000 22.0 0.09999999999985551\n","312500 23.4 0.09999999999985551\n","313000 24.3 0.09999999999985551\n","313500 22.2 0.09999999999985551\n","314000 20.8 0.09999999999985551\n","314500 23.4 0.09999999999985551\n","315000 22.6 0.09999999999985551\n","315500 20.2 0.09999999999985551\n","316000 21.8 0.09999999999985551\n","316500 23.4 0.09999999999985551\n","317000 22.4 0.09999999999985551\n","317500 17.9 0.09999999999985551\n","318000 23.7 0.09999999999985551\n","318500 22.3 0.09999999999985551\n","319000 23.7 0.09999999999985551\n","319500 22.1 0.09999999999985551\n","320000 23.2 0.09999999999985551\n","320500 21.8 0.09999999999985551\n","321000 22.7 0.09999999999985551\n","321500 22.5 0.09999999999985551\n","322000 23.4 0.09999999999985551\n","322500 22.7 0.09999999999985551\n","323000 21.9 0.09999999999985551\n","323500 20.6 0.09999999999985551\n","324000 22.5 0.09999999999985551\n","324500 22.8 0.09999999999985551\n","325000 21.9 0.09999999999985551\n","325500 20.1 0.09999999999985551\n","326000 22.3 0.09999999999985551\n","326500 20.8 0.09999999999985551\n","327000 22.7 0.09999999999985551\n","327500 22.4 0.09999999999985551\n","328000 20.6 0.09999999999985551\n","328500 20.1 0.09999999999985551\n","329000 23.3 0.09999999999985551\n","329500 20.0 0.09999999999985551\n","330000 23.9 0.09999999999985551\n","330500 21.4 0.09999999999985551\n","331000 21.4 0.09999999999985551\n","331500 24.7 0.09999999999985551\n","332000 21.6 0.09999999999985551\n","332500 22.6 0.09999999999985551\n","333000 22.9 0.09999999999985551\n","333500 23.4 0.09999999999985551\n","334000 21.3 0.09999999999985551\n","334500 23.4 0.09999999999985551\n","335000 23.3 0.09999999999985551\n","335500 21.4 0.09999999999985551\n","336000 23.5 0.09999999999985551\n","336500 21.3 0.09999999999985551\n","337000 21.5 0.09999999999985551\n","337500 22.1 0.09999999999985551\n","338000 21.8 0.09999999999985551\n","338500 21.0 0.09999999999985551\n","339000 21.8 0.09999999999985551\n","339500 23.1 0.09999999999985551\n","340000 22.8 0.09999999999985551\n","340500 20.0 0.09999999999985551\n","341000 22.2 0.09999999999985551\n","341500 21.1 0.09999999999985551\n","342000 24.3 0.09999999999985551\n","342500 21.5 0.09999999999985551\n","343000 22.6 0.09999999999985551\n","343500 19.7 0.09999999999985551\n","344000 22.0 0.09999999999985551\n","344500 19.9 0.09999999999985551\n","345000 19.7 0.09999999999985551\n","345500 22.2 0.09999999999985551\n","346000 22.3 0.09999999999985551\n","346500 21.2 0.09999999999985551\n","347000 23.1 0.09999999999985551\n","347500 20.7 0.09999999999985551\n","348000 23.2 0.09999999999985551\n","348500 23.0 0.09999999999985551\n","349000 24.0 0.09999999999985551\n","349500 22.2 0.09999999999985551\n","350000 19.9 0.09999999999985551\n","Saved Model\n","350500 20.1 0.09999999999985551\n","351000 22.7 0.09999999999985551\n","351500 21.4 0.09999999999985551\n","352000 21.8 0.09999999999985551\n","352500 22.8 0.09999999999985551\n","353000 22.1 0.09999999999985551\n","353500 23.8 0.09999999999985551\n","354000 24.2 0.09999999999985551\n","354500 22.4 0.09999999999985551\n","355000 23.1 0.09999999999985551\n","355500 22.7 0.09999999999985551\n","356000 21.5 0.09999999999985551\n","356500 22.3 0.09999999999985551\n","357000 22.7 0.09999999999985551\n","357500 22.0 0.09999999999985551\n","358000 22.4 0.09999999999985551\n","358500 22.1 0.09999999999985551\n","359000 21.6 0.09999999999985551\n","359500 22.0 0.09999999999985551\n","360000 22.8 0.09999999999985551\n","360500 22.1 0.09999999999985551\n","361000 20.8 0.09999999999985551\n","361500 22.7 0.09999999999985551\n","362000 23.7 0.09999999999985551\n","362500 23.0 0.09999999999985551\n","363000 20.3 0.09999999999985551\n","363500 20.7 0.09999999999985551\n","364000 23.4 0.09999999999985551\n","364500 22.0 0.09999999999985551\n","365000 23.5 0.09999999999985551\n","365500 21.1 0.09999999999985551\n","366000 23.2 0.09999999999985551\n","366500 21.2 0.09999999999985551\n","367000 21.6 0.09999999999985551\n","367500 22.1 0.09999999999985551\n","368000 21.7 0.09999999999985551\n","368500 19.8 0.09999999999985551\n","369000 21.0 0.09999999999985551\n","369500 22.5 0.09999999999985551\n","370000 21.7 0.09999999999985551\n","370500 23.4 0.09999999999985551\n","371000 22.4 0.09999999999985551\n","371500 22.8 0.09999999999985551\n","372000 23.7 0.09999999999985551\n","372500 22.2 0.09999999999985551\n","373000 23.1 0.09999999999985551\n","373500 21.8 0.09999999999985551\n","374000 22.0 0.09999999999985551\n","374500 20.5 0.09999999999985551\n","375000 22.8 0.09999999999985551\n","375500 21.7 0.09999999999985551\n","376000 24.6 0.09999999999985551\n","376500 24.9 0.09999999999985551\n","377000 23.2 0.09999999999985551\n","377500 22.0 0.09999999999985551\n","378000 22.7 0.09999999999985551\n","378500 23.0 0.09999999999985551\n","379000 23.4 0.09999999999985551\n","379500 21.8 0.09999999999985551\n","380000 23.7 0.09999999999985551\n","380500 19.7 0.09999999999985551\n","381000 24.1 0.09999999999985551\n","381500 22.0 0.09999999999985551\n","382000 22.2 0.09999999999985551\n","382500 21.5 0.09999999999985551\n","383000 21.1 0.09999999999985551\n","383500 22.6 0.09999999999985551\n","384000 22.7 0.09999999999985551\n","384500 20.7 0.09999999999985551\n","385000 23.0 0.09999999999985551\n","385500 22.5 0.09999999999985551\n","386000 23.9 0.09999999999985551\n","386500 20.6 0.09999999999985551\n","387000 23.5 0.09999999999985551\n","387500 21.3 0.09999999999985551\n","388000 19.7 0.09999999999985551\n","388500 22.9 0.09999999999985551\n","389000 21.7 0.09999999999985551\n","389500 21.3 0.09999999999985551\n","390000 24.4 0.09999999999985551\n","390500 23.2 0.09999999999985551\n","391000 23.0 0.09999999999985551\n","391500 22.1 0.09999999999985551\n","392000 21.5 0.09999999999985551\n","392500 21.7 0.09999999999985551\n","393000 24.3 0.09999999999985551\n","393500 22.9 0.09999999999985551\n","394000 22.7 0.09999999999985551\n","394500 23.4 0.09999999999985551\n","395000 22.1 0.09999999999985551\n","395500 21.6 0.09999999999985551\n","396000 23.4 0.09999999999985551\n","396500 22.4 0.09999999999985551\n","397000 22.8 0.09999999999985551\n","397500 22.4 0.09999999999985551\n","398000 22.8 0.09999999999985551\n","398500 21.9 0.09999999999985551\n","399000 24.3 0.09999999999985551\n","399500 23.7 0.09999999999985551\n","400000 21.6 0.09999999999985551\n","Saved Model\n","400500 22.7 0.09999999999985551\n","401000 20.3 0.09999999999985551\n","401500 22.8 0.09999999999985551\n","402000 22.5 0.09999999999985551\n","402500 21.3 0.09999999999985551\n","403000 21.3 0.09999999999985551\n","403500 20.4 0.09999999999985551\n","404000 21.8 0.09999999999985551\n","404500 20.9 0.09999999999985551\n","405000 23.1 0.09999999999985551\n","405500 23.3 0.09999999999985551\n","406000 21.6 0.09999999999985551\n","406500 22.9 0.09999999999985551\n","407000 21.3 0.09999999999985551\n","407500 22.2 0.09999999999985551\n","408000 22.1 0.09999999999985551\n","408500 23.1 0.09999999999985551\n","409000 22.3 0.09999999999985551\n","409500 24.9 0.09999999999985551\n","410000 23.2 0.09999999999985551\n","410500 21.6 0.09999999999985551\n","411000 23.3 0.09999999999985551\n","411500 22.7 0.09999999999985551\n","412000 21.9 0.09999999999985551\n","412500 23.8 0.09999999999985551\n","413000 20.9 0.09999999999985551\n","413500 22.0 0.09999999999985551\n","414000 23.1 0.09999999999985551\n","414500 22.1 0.09999999999985551\n","415000 22.6 0.09999999999985551\n","415500 22.0 0.09999999999985551\n","416000 23.4 0.09999999999985551\n","416500 22.9 0.09999999999985551\n","417000 23.5 0.09999999999985551\n","417500 20.4 0.09999999999985551\n","418000 23.4 0.09999999999985551\n","418500 22.7 0.09999999999985551\n","419000 22.3 0.09999999999985551\n","419500 22.1 0.09999999999985551\n","420000 20.3 0.09999999999985551\n","420500 21.8 0.09999999999985551\n","421000 22.6 0.09999999999985551\n","421500 22.6 0.09999999999985551\n","422000 21.8 0.09999999999985551\n","422500 21.2 0.09999999999985551\n","423000 22.0 0.09999999999985551\n","423500 21.5 0.09999999999985551\n","424000 22.4 0.09999999999985551\n","424500 25.4 0.09999999999985551\n","425000 21.8 0.09999999999985551\n","425500 21.4 0.09999999999985551\n","426000 22.4 0.09999999999985551\n","426500 21.3 0.09999999999985551\n","427000 23.0 0.09999999999985551\n","427500 22.1 0.09999999999985551\n","428000 21.3 0.09999999999985551\n","428500 22.7 0.09999999999985551\n","429000 20.6 0.09999999999985551\n","429500 21.8 0.09999999999985551\n","430000 24.1 0.09999999999985551\n","430500 23.2 0.09999999999985551\n","431000 20.9 0.09999999999985551\n","431500 22.8 0.09999999999985551\n","432000 22.8 0.09999999999985551\n","432500 20.0 0.09999999999985551\n","433000 24.0 0.09999999999985551\n","433500 21.5 0.09999999999985551\n","434000 22.3 0.09999999999985551\n","434500 23.3 0.09999999999985551\n","435000 23.3 0.09999999999985551\n","435500 22.6 0.09999999999985551\n","436000 20.5 0.09999999999985551\n","436500 24.3 0.09999999999985551\n","437000 23.3 0.09999999999985551\n","437500 23.7 0.09999999999985551\n","438000 24.4 0.09999999999985551\n","438500 22.4 0.09999999999985551\n","439000 21.9 0.09999999999985551\n","439500 21.0 0.09999999999985551\n","440000 23.1 0.09999999999985551\n","440500 22.3 0.09999999999985551\n","441000 24.0 0.09999999999985551\n","441500 22.5 0.09999999999985551\n","442000 22.5 0.09999999999985551\n","442500 24.0 0.09999999999985551\n","443000 23.9 0.09999999999985551\n","443500 22.2 0.09999999999985551\n","444000 23.1 0.09999999999985551\n","444500 24.2 0.09999999999985551\n","445000 23.9 0.09999999999985551\n","445500 21.9 0.09999999999985551\n","446000 21.7 0.09999999999985551\n","446500 22.7 0.09999999999985551\n","447000 23.4 0.09999999999985551\n","447500 23.8 0.09999999999985551\n","448000 23.0 0.09999999999985551\n","448500 20.7 0.09999999999985551\n","449000 22.3 0.09999999999985551\n","449500 22.5 0.09999999999985551\n","450000 21.4 0.09999999999985551\n","Saved Model\n","450500 20.9 0.09999999999985551\n","451000 22.8 0.09999999999985551\n","451500 23.7 0.09999999999985551\n","452000 19.6 0.09999999999985551\n","452500 23.6 0.09999999999985551\n","453000 23.7 0.09999999999985551\n","453500 23.0 0.09999999999985551\n","454000 21.0 0.09999999999985551\n","454500 20.1 0.09999999999985551\n","455000 22.3 0.09999999999985551\n","455500 23.4 0.09999999999985551\n","456000 21.6 0.09999999999985551\n","456500 22.0 0.09999999999985551\n","457000 21.1 0.09999999999985551\n","457500 24.1 0.09999999999985551\n","458000 22.1 0.09999999999985551\n","458500 24.4 0.09999999999985551\n","459000 21.8 0.09999999999985551\n","459500 23.2 0.09999999999985551\n","460000 20.1 0.09999999999985551\n","460500 21.3 0.09999999999985551\n","461000 21.1 0.09999999999985551\n","461500 22.9 0.09999999999985551\n","462000 22.3 0.09999999999985551\n","462500 24.9 0.09999999999985551\n","463000 24.4 0.09999999999985551\n","463500 22.0 0.09999999999985551\n","464000 23.1 0.09999999999985551\n","464500 20.9 0.09999999999985551\n","465000 22.6 0.09999999999985551\n","465500 22.7 0.09999999999985551\n","466000 23.8 0.09999999999985551\n","466500 22.0 0.09999999999985551\n","467000 25.7 0.09999999999985551\n","467500 22.9 0.09999999999985551\n","468000 24.2 0.09999999999985551\n","468500 22.7 0.09999999999985551\n","469000 23.5 0.09999999999985551\n","469500 23.3 0.09999999999985551\n","470000 22.7 0.09999999999985551\n","470500 21.7 0.09999999999985551\n","471000 23.2 0.09999999999985551\n","471500 20.9 0.09999999999985551\n","472000 22.9 0.09999999999985551\n","472500 23.3 0.09999999999985551\n","473000 23.6 0.09999999999985551\n","473500 23.7 0.09999999999985551\n","474000 23.7 0.09999999999985551\n","474500 21.3 0.09999999999985551\n","475000 21.9 0.09999999999985551\n","475500 21.8 0.09999999999985551\n","476000 23.1 0.09999999999985551\n","476500 21.1 0.09999999999985551\n","477000 21.3 0.09999999999985551\n","477500 23.6 0.09999999999985551\n","478000 21.8 0.09999999999985551\n","478500 22.5 0.09999999999985551\n","479000 20.9 0.09999999999985551\n","479500 20.2 0.09999999999985551\n","480000 21.7 0.09999999999985551\n","480500 24.1 0.09999999999985551\n","481000 23.1 0.09999999999985551\n","481500 22.8 0.09999999999985551\n","482000 23.3 0.09999999999985551\n","482500 23.2 0.09999999999985551\n","483000 21.9 0.09999999999985551\n","483500 23.6 0.09999999999985551\n","484000 21.7 0.09999999999985551\n","484500 22.0 0.09999999999985551\n","485000 24.7 0.09999999999985551\n","485500 23.7 0.09999999999985551\n","486000 22.0 0.09999999999985551\n","486500 20.9 0.09999999999985551\n","487000 22.7 0.09999999999985551\n","487500 21.9 0.09999999999985551\n","488000 21.9 0.09999999999985551\n","488500 22.3 0.09999999999985551\n","489000 22.2 0.09999999999985551\n","489500 20.4 0.09999999999985551\n","490000 22.3 0.09999999999985551\n","490500 23.6 0.09999999999985551\n","491000 22.4 0.09999999999985551\n","491500 25.4 0.09999999999985551\n","492000 22.6 0.09999999999985551\n","492500 22.6 0.09999999999985551\n","493000 20.1 0.09999999999985551\n","493500 23.5 0.09999999999985551\n","494000 21.1 0.09999999999985551\n","494500 23.6 0.09999999999985551\n","495000 20.5 0.09999999999985551\n","495500 24.9 0.09999999999985551\n","496000 21.4 0.09999999999985551\n","496500 22.0 0.09999999999985551\n","497000 22.3 0.09999999999985551\n","497500 22.7 0.09999999999985551\n","498000 22.3 0.09999999999985551\n","498500 24.2 0.09999999999985551\n","499000 20.9 0.09999999999985551\n","499500 22.4 0.09999999999985551\n","500000 23.4 0.09999999999985551\n","Percent of succesful episodes: 17.506%\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f3e729cba90>]"]},"metadata":{"tags":[]},"execution_count":1},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATMAAAD8CAYAAAAbkUOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niHiCwkxEPEFhJiKeoDATEU/4/4RwRfemLawIAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9C3dSIpX_ujO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}